{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purplecat24/GPT2-API-Clouds/blob/main/Clouds_GPT_2022_2_09_Lav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG3Udvq92rgL"
      },
      "source": [
        "# Clouds (with custom tune)\n",
        "\n",
        "Generate text with GPT-2, using a custom wrapper around [Max Woolf](http://minimaxir.com)'s `gpt_2_simple`. as well as Anna Garbier and Lavannya Surresh's customizations for the game, Cloud Theory."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Gradio"
      ],
      "metadata": {
        "id": "1jIGGXC0aARG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFcF9NOjZ_-g",
        "outputId": "427490b5-8357-41e0-92d6-0d81946e1abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.8.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 17.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Collecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting websockets\n",
            "  Downloading websockets-10.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 69.7 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.10.0)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.19.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.85.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Collecting starlette==0.20.4\n",
            "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 11.1 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (2022.9.24)\n",
            "Collecting httpcore<0.16.0,>=0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gradio) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.5)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 53.7 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=63e79581bd3ce49fcda063ea3186b55637d330303490e89359ec4fc37663a9d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=d8604734d04bb7e99ee268a713ea383cf9fadc794587fd701d93faa253131c37\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, ffmpy, fastapi, gradio\n",
            "Successfully installed anyio-3.6.2 bcrypt-4.0.1 cryptography-38.0.3 fastapi-0.85.2 ffmpy-0.3.0 gradio-3.8.2 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.1 mdurl-0.1.2 orjson-3.8.1 paramiko-2.11.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.20.4 uc-micro-py-1.0.1 uvicorn-0.19.0 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch App"
      ],
      "metadata": {
        "id": "AxkT87yyapXt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyDejqulUx-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "##  1. Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf31834-539b-42fe-b010-6da6688d7c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7sNA9tCHvIz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset \n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oSC2sE6eE-uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb38cb0-1123-4cfd-ebc5-5c871e0e44aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE9JFMetWM0s"
      },
      "source": [
        "## 2. Make sure the notebook is running on GPU\n",
        "\n",
        "Run the following cell. If you get an error like `NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver...`, then follow [these instructions](https://stackoverflow.com/questions/62697331/nvidia-smi-has-failed-because-it-couldnt-communicate-with-the-nvidia-driver-ma)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6VJzArLVrM-",
        "outputId": "f52a4257-cb87-4402-87e7-72edc6c30420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 18 01:53:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## 3. Download GPT-2 (skip to step 9 if using pre-trained model)\n",
        "\n",
        "There are several versions of GPT-2 (124M, 355M, 774M, 1558M). This notebook uses the 355M version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ8-P0qMM0hE",
        "outputId": "147a0aa5-2bae-499a-8076-6cb4c553baf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 382Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 568kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 288Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:22, 6.05Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 405Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 724kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 846kit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy078tEn17zf"
      },
      "source": [
        "## 4. Mount Drive\n",
        "\n",
        "Give the runtime temporary access to read from / write to Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rpuTjlEMzJn",
        "outputId": "06b11bf8-059d-49de-e1c0-626adf9c8e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "gpt2.mount_gdrive()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt-carzN3bsg"
      },
      "source": [
        "## 5. Copy tuning text from Drive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PqqOqwO3du8"
      },
      "outputs": [],
      "source": [
        "file_name = \"russell.txt\"\n",
        "run_name = 'fine_tuning_run_2'\n",
        "model_size = '124M'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbmhHpRbKvB6"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDrKCzVOGe3o",
        "outputId": "ad487e5c-28dc-49c5-f676-99fdb9a0de70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mflagged\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  russell.txt  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbTft8Gm4D5k"
      },
      "source": [
        "## 6. Tune GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaKkObTm4HUP",
        "outputId": "1c867099-289d-4477-d0ec-59f9a9583e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 61042 tokens\n",
            "Training...\n",
            "[10 | 27.58] loss=2.82 avg=2.82\n",
            "[20 | 48.93] loss=2.31 avg=2.56\n",
            "[30 | 70.60] loss=2.38 avg=2.50\n",
            "[40 | 92.51] loss=2.39 avg=2.47\n",
            "[50 | 114.70] loss=2.06 avg=2.39\n",
            "[60 | 137.17] loss=2.01 avg=2.32\n",
            "[70 | 159.83] loss=1.46 avg=2.20\n",
            "[80 | 182.67] loss=1.73 avg=2.14\n",
            "[90 | 205.66] loss=1.41 avg=2.05\n",
            "[100 | 228.78] loss=1.21 avg=1.96\n",
            "[110 | 252.06] loss=1.42 avg=1.91\n",
            "[120 | 275.47] loss=0.86 avg=1.82\n",
            "[130 | 299.05] loss=1.06 avg=1.76\n",
            "[140 | 322.71] loss=0.68 avg=1.67\n",
            "[150 | 346.36] loss=0.51 avg=1.59\n",
            "[160 | 370.07] loss=0.35 avg=1.51\n",
            "[170 | 393.78] loss=0.49 avg=1.44\n",
            "[180 | 417.53] loss=0.64 avg=1.39\n",
            "[190 | 441.25] loss=0.42 avg=1.34\n",
            "[200 | 464.98] loss=0.17 avg=1.27\n",
            "======== SAMPLE 1 ========\n",
            ":\n",
            "a) To have knowledge\n",
            "is to have a common object, namely, to have a knowledge of\n",
            "knowledge. _b) Knowledge generally involves a knowledge of truths,\n",
            "but differs from knowledge in its object and its degree. A deceitful man\n",
            "may buy the truth of the goods said to be trustworthy, and deceive his\n",
            "couple. But if the goods are essentially the same, the man who bought\n",
            "the goods may well be judged to have a knowledge of the truths concerned;\n",
            "but the man who did not buy the goods may well have a knowledge\n",
            "only of the truths concerned.\n",
            "\n",
            "Thus a truth is a true judgement in itself, but of its\n",
            "particularity, its degree, in the presence of other things,\n",
            "whereas a truth of the sort concerned is only truly known\n",
            "in the case of the judgement made about the things being\n",
            "judged.\n",
            "\n",
            "We asked what things are, what things are in the world, what\n",
            "are the particulars of our question, we should have commonly received\n",
            "the immediate and definite proposition 'there is\n",
            "such-and-such-thing', or 'there is such-and-such-thing-being'. Either\n",
            "we can now give the direct proposition 'there is such-and-such-thing', or\n",
            "we can give an indirect proposition 'the object of our\n",
            "question is such-and-such-thing'. We can both of course give an\n",
            "opposition, because of the fact that the proposition 'thing A is\n",
            "such-and-such-thing' is opposed to 'thing B, and then A and\n",
            "C and then C and then C', but both of them will give an\n",
            "opposition on the principle that whatever we can give an\n",
            "object of the form 'A' must be something' must be opposed,\n",
            "on the principle that nothing can be known immediately except by\n",
            "passages in the mind. We think of knowledge as opposed to\n",
            "knowledge as opposed to _criticism_. It is clear that\n",
            "the proposition 'there is such-and-such-thing' is opposed to\n",
            "criticism, since it is opposed to the criticism of A.\n",
            "The same thing applies to 'belief'. It is opposed to _belief_,\n",
            "where faith is opposed to _belief_. Now there is no very\n",
            "repetitious proposition, however well understood, which says _there_\n",
            "is_ such-and-such-thing_. It is not truth which is rejected, but the\n",
            "immediate object of belief, THE BEING. If there were such an\n",
            "idea, our knowledge of it would be incomplete, and there would be no\n",
            "evidence that could lead us to it. This is why it is important to\n",
            "possess some reason for regarding knowledge as opposed to _judging_.\n",
            "\n",
            "By what reasons have we to been led to doubt the _existence_ of\n",
            "white things? What reason have they for continuing to exist? But first of\n",
            "the very same reasons which led us to suspect that there were white\n",
            "things some 100,000 years ago. Such doubts as these are not\n",
            "resistant to more general arguments from what may be, and still remain,\n",
            "practical and empirical reasons. For this reason alone it is unavailing\n",
            "to regard argument from reason as the fundamental principle of science.<|endoftext|>The problem of the\n",
            "'whiteness of soul'\n",
            "has been with us for many years, and has for many different\n",
            "thoughts. But it is time to look more closely at the\n",
            "problem from a different point of view. We have seen, in the preceding\n",
            "chapter, that even the whitest colour is not a perfectly\n",
            "matrix, and also so is not all the colour. Thus, e.g.,\n",
            "we read: 'O the great city of God, how many inhabitants of this\n",
            "community are there?' 'Many millions', quoth the earwig, 'and who is\n",
            "the representative there?' The whitest colour will have to be among\n",
            "the many particulars known to us, since, conversely, the infinity\n",
            "which our intellect can imagine unites all these particulars together.'\n",
            "\n",
            "Such a view of the problem, which I originally supposed to be merely a\n",
            "product of human error, has now become a very powerful one, and many\n",
            "philosophers and laymen are persuaded that it is not so. In fact, while\n",
            "throwing doubt on the view which had led them, we may\n",
            "also wish to examine the reasons which have surrounded the view\n",
            "which has led us.\n",
            "\n",
            "The first answer to the above suggested cause, that _all_ of existence\n",
            "should be known by name, is that knowledge always requires a cause\n",
            "named some knowledge_, and it is obvious that this is not what\n",
            "we have been trying to say. Knowledge of a cause is called\n",
            "knowledge of a form, and a being known by name is called a\n",
            "_particular_. A particular in this case is called the\n",
            "\n",
            "[210 | 501.49] loss=0.24 avg=1.22\n",
            "[220 | 525.26] loss=0.18 avg=1.17\n",
            "[230 | 549.03] loss=0.16 avg=1.12\n",
            "[240 | 572.78] loss=0.27 avg=1.08\n",
            "[250 | 596.53] loss=0.13 avg=1.04\n",
            "[260 | 620.24] loss=0.10 avg=1.00\n",
            "[270 | 644.00] loss=0.13 avg=0.96\n",
            "[280 | 667.71] loss=0.10 avg=0.92\n",
            "[290 | 691.44] loss=0.08 avg=0.89\n",
            "[300 | 715.17] loss=0.09 avg=0.86\n",
            "[310 | 738.89] loss=0.11 avg=0.83\n",
            "[320 | 762.64] loss=0.10 avg=0.81\n",
            "[330 | 786.34] loss=0.11 avg=0.78\n",
            "[340 | 810.09] loss=0.08 avg=0.76\n",
            "[350 | 833.84] loss=0.09 avg=0.73\n",
            "[360 | 857.57] loss=0.06 avg=0.71\n",
            "[370 | 881.28] loss=0.09 avg=0.69\n",
            "[380 | 904.97] loss=0.08 avg=0.67\n",
            "[390 | 928.70] loss=0.07 avg=0.65\n",
            "[400 | 952.39] loss=0.09 avg=0.64\n",
            "======== SAMPLE 1 ========\n",
            " provision\n",
            "a new point from which to begin, as we saw in the\n",
            "piecemeal consideration of the principles by which philosophy deals. But,\n",
            "mainly because of our difficulty in seeing why so many men\n",
            "end up in the Royal Institution than any other, the fact is────\n",
            "that even on a comparative basis such a theory would only make a\n",
            "whole theory of justice look less probable than a theory of law.\n",
            "\n",
            "In fact, the most I can learn from experience is that even where\n",
            "we find law and reason, law and reason, there is no law which\n",
            "can be fully explained by experience; and although in some way or other we\n",
            "found the laws to be rather too complicated to understand, just as easily\n",
            "we will find the reasoning to be too complex to understand. Thus, although\n",
            "philosophy should be something very simple and innocent, while at the same time being\n",
            "something which leaves much of the thought of what is--or is not--a mere\n",
            "memory, thought of the laws seems to be going to be going to a place where\n",
            "practical knowledge is not just common sense, but is going to be common\n",
            "knowledge. Wherein philosophy finds the _a priori_ question of\n",
            "practical knowledge, namely, as it turns out, also the question of the\n",
            "existence of matter and its relations. Has there been any doubt as\n",
            "to the truth or falsehood of this question? And if so, has the question of\n",
            "matter relation even greater doubt? This is a question with which\n",
            "philosophy begins with us, and which goes back to our very conception\n",
            "of the world. If we are to understand the question as we are seeing it,\n",
            "there is no doubt that we must answer it by means of some approach to\n",
            "the truth or falsehood of the proposition we are asking. That is to say, if\n",
            "we are to understand the proposition, we must be able to answer the\n",
            "question in a certain way, and if we are not, we must be asking the\n",
            "problem of its solution. This is the essence of the proposition\n",
            "\"Nothing can be known to be _not_ aether.\"\n",
            "\n",
            "The proposition \"Nothing can be known to be _not_ aether\"\n",
            "means: (1) Nothing can be known to be _not_ aether, (2) Ether cannot be\n",
            "hearted or dried up, (3) No amount of knowledge about the universe\n",
            "can satisfy our knowledge of the words \"there\" and \"me\"; (4) Nothing can\n",
            "be known to be _not_ aether, but must be of a different order from the\n",
            "facts known to be in the order that it is known by us. This is further\n",
            "remained constant as we move along the investigations into the\n",
            "dark recesses of the human brain.\n",
            "\n",
            "Any theory of knowledge which retains the order of knowledge suggested\n",
            "by the previous chapter has its parts disturbed, and new facts\n",
            "concluded. But although this principle is at once practical and political,\n",
            "hence it is not important what bit of knowledge which we require, and\n",
            "does not involve any expenditure of time or money. The principle is just, and is just as\n",
            "practical in application to any matter as it is in the removal of useless\n",
            "propositions from the study of knowledge.\n",
            "\n",
            "What follows is a copy of Chapter IV of the Theoretical\n",
            "Principles of Philosophy, prepared by Professor Gilbert of York,\n",
            "and endorsed by the Chapter. It is largely correct, in fact, that\n",
            "theoreticians should introduce the principle of\n",
            "selection as an element in their theory of knowledge, though it is\n",
            "by no means necessary. It is only when, through reason, we come to see\n",
            "that the principle as it is used is completely different. When, for example,\n",
            "we see that rivers flow along hillsides, we do not, in fact, feel the\n",
            "possibility of a relation between the relation and the relation; we feel that the\n",
            "resemblance is not operative, but only patronizing; and finally, we feel that\n",
            "the relation is not capable of surviving the lapse of a century.\n",
            "\n",
            "But in spite of the fact that the principle is useful in such matters,\n",
            "it is not widely held that mankind ever will feel the word\n",
            "'idea' or 'proposal', or even that it is ever used in a metaphysically sound\n",
            "measure. The most we can hope is that by inventing a better phrase,\n",
            "we shall be able to bring ourselves to accept the principle more fully than we\n",
            "were able to accept the proposition itself. For this hope has not been achieved\n",
            "completely, but may be indicated as modern day.\n",
            "\n",
            "The fact is that, in much the same way that we may perceive that a\n",
            "large patch of dark matter is making us dream, and in much the same way we may\n",
            "soar through a patch of light, but we do not seem to be able to\n",
            "know\n",
            "\n",
            "[410 | 986.53] loss=0.07 avg=0.62\n",
            "[420 | 1010.19] loss=0.06 avg=0.60\n",
            "[430 | 1033.85] loss=0.05 avg=0.59\n",
            "[440 | 1057.52] loss=0.08 avg=0.57\n",
            "[450 | 1081.19] loss=0.07 avg=0.56\n",
            "[460 | 1104.89] loss=0.08 avg=0.55\n",
            "[470 | 1128.54] loss=0.06 avg=0.53\n",
            "[480 | 1152.25] loss=0.06 avg=0.52\n",
            "[490 | 1175.91] loss=0.05 avg=0.51\n",
            "[500 | 1199.61] loss=0.06 avg=0.50\n",
            "Saving checkpoint/fine_tuning_run_2/model-500\n",
            "[510 | 1226.00] loss=0.05 avg=0.49\n",
            "[520 | 1249.78] loss=0.06 avg=0.48\n",
            "[530 | 1273.47] loss=0.06 avg=0.47\n",
            "[540 | 1297.09] loss=0.05 avg=0.46\n",
            "[550 | 1320.73] loss=0.07 avg=0.45\n",
            "[560 | 1344.40] loss=0.05 avg=0.44\n",
            "[570 | 1368.08] loss=0.07 avg=0.43\n",
            "[580 | 1391.74] loss=0.04 avg=0.42\n",
            "[590 | 1415.41] loss=0.06 avg=0.41\n",
            "[600 | 1439.07] loss=0.05 avg=0.40\n",
            "======== SAMPLE 1 ========\n",
            ", as I have now more or less seen from my own, and have often\n",
            "perceived what is really taken, provided there is no obvious\n",
            "direction from which it must travel. Also the fact that physical objects seem to\n",
            "travel in a straight line, as opposed to a straight line, is\n",
            "obviously a relation of the senses, and is taken as a sign of the\n",
            "actual location of the object. But for our demonstration that\n",
            "there is a physical straight line, we must try to see, from\n",
            "some other point of view, that which we know to be straight. We have\n",
            "therefore to look without success, until we come to some realization\n",
            "of the unity of the objective sense, which we call 'seeing'. There is\n",
            "no easy and easy guide, therefore, except perhaps by the disputation\n",
            "which comes from looking at something which has been saw or has had a look\n",
            "at, or has some other perception which is competent to judge of\n",
            "the object described. Thus the only thing humanly possible to\n",
            "fail from failure is the object. But so long as this is the case,\n",
            "failure has been a constant part of human experience, and has been\n",
            "therefore only possible when the object is not in itself known to\n",
            "experience. Failure to know this failure shall be a mark of\n",
            "rapism, and a mark of cowardice, and a severe affront to the\n",
            "wisdom of God.\n",
            "\n",
            "It will serve to give a brief history of what is meant by\n",
            "failure, in order that we may be able to examine its scope and\n",
            "prejudice as it applies to our own life and work. In the following pages we\n",
            "have to consider what is meant by 'failure' and 'failureism', and how\n",
            "it applies to the lives of others.\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER IV. IDEALISM AND PUNITIVE IDEALISM\n",
            "\n",
            "In the preceding chapter we saw that there are two sorts of idealism\n",
            "and inconsistent altruism, and that there is an inner world which is\n",
            "perfectly\n",
            "independent of any particular man. In this chapter we shall merely\n",
            "begere (sit) upon) as our criterion of idealism. Idealism\n",
            "is that which is universal, and only so long as there is such\n",
            "an object as our own. It is supposed that there are inanimate objects\n",
            "which do not see the table nor hear the calls. If this were so, we should\n",
            "bethink ourselves acquainted with the world of universals, which we\n",
            "shall call 'parts'. The real world, full of unreal things, we cannot account\n",
            "for or understand, for which we have so farunachable qualities. In one\n",
            "way or another, we shall be compelled to accept the belief as true, unless,\n",
            "it is said, there are enough objects for the mind, and\n",
            "therefore there is. The part which believes the view, though it exists\n",
            "in a separate world, is nevertheless part of the world which deserves to be\n",
            "known; and it is only in this world that we have private experiences,\n",
            "in which we have an experience of what it is like to be part of\n",
            "a distinct world.\n",
            "\n",
            "The word 'idea' has acquired, in the course of time, many associations\n",
            "which are quite misleading when applied to Plato's 'ideas'. We shall\n",
            "therefore use the word 'universal' instead of the word 'idea', to\n",
            "describe what Plato meant. The essence of the sort of entity that Plato\n",
            "meant is that it is opposed to the particular things that are given in\n",
            "sensation. We speak of whatever is given in sensation, or is of the same\n",
            "nature as things given in sensation, as a _particular_; by opposition\n",
            "to this, a _universal_ will be anything which may be shared by many\n",
            "particulars, and has those characteristics which, as we saw, distinguish\n",
            "justice and whiteness from just acts and white things.\n",
            "\n",
            "When we examine common words, we find that, broadly speaking, proper\n",
            "names stand for particulars, while other substantives, adjectives,\n",
            "prepositions, and verbs stand for universals. Pronouns stand for\n",
            "particulars, but are ambiguous: it is only by the context or the\n",
            "circumstances that we know what particulars they stand for. The word\n",
            "'now' stands for a particular, namely the present moment; but like\n",
            "pronouns, it stands for an ambiguous particular, because the present is\n",
            "always changing.\n",
            "\n",
            "It will be seen that no sentence can be made up without at least one\n",
            "word which denotes a universal. The nearest approach would be some such\n",
            "statement as 'I like this'. But even here the word 'like' denotes\n",
            "a universal, for I may like other things, and other people may like\n",
            "things. Thus all truths involve universals, and all knowledge of truths\n",
            "involves acquaintance with universals\n",
            "\n",
            "[610 | 1473.15] loss=0.07 avg=0.40\n",
            "[620 | 1496.80] loss=0.06 avg=0.39\n",
            "[630 | 1520.50] loss=0.06 avg=0.38\n",
            "[640 | 1544.16] loss=0.05 avg=0.38\n",
            "[650 | 1567.88] loss=0.06 avg=0.37\n",
            "[660 | 1591.62] loss=0.05 avg=0.36\n",
            "[670 | 1615.33] loss=0.04 avg=0.36\n",
            "[680 | 1639.07] loss=0.06 avg=0.35\n",
            "[690 | 1662.79] loss=0.06 avg=0.34\n",
            "[700 | 1686.54] loss=0.05 avg=0.34\n",
            "[710 | 1710.27] loss=0.04 avg=0.33\n",
            "[720 | 1734.03] loss=0.05 avg=0.33\n",
            "[730 | 1757.81] loss=0.05 avg=0.32\n",
            "[740 | 1781.52] loss=0.05 avg=0.32\n",
            "[750 | 1805.27] loss=0.05 avg=0.31\n",
            "[760 | 1828.96] loss=0.06 avg=0.31\n",
            "[770 | 1852.69] loss=0.03 avg=0.30\n",
            "[780 | 1876.38] loss=0.04 avg=0.30\n",
            "[790 | 1900.06] loss=0.04 avg=0.29\n",
            "[800 | 1923.78] loss=0.04 avg=0.29\n",
            "======== SAMPLE 1 ========\n",
            " some problems which are of much less importance than we\n",
            "realize it, and this neglect of important ones diminishes the\n",
            "ambiguity which philosophy has for ordinary people. The man who is ignorant of philosophy\n",
            "will at last become aware of its importance, and in time, people who have never been\n",
            "educated in the philosophy of mathematics, or who have never been able to grasp the\n",
            "logic of mathematics, will be convinced that the law of contradiction forbids\n",
            "this law of contradiction, and that therefore everything that can be proved\n",
            "by it must be in some sense erroneous.\n",
            "\n",
            "philosophy, like all other studies, aims primarily at knowledge. The\n",
            "knowledge it aims at is the kind of knowledge which gives unity and\n",
            "system to the body of negative knowledge, and the sort of knowledge which results from\n",
            "discourse even when no opinion is expressed nor is it constructive. It is\n",
            "this kind of knowledge which constitutes the value of philosophy.\n",
            "According to the philosophers who have preceded the school, truth was the\n",
            "great liberator, goodness the liberator; the only two sorts of wisdom produced\n",
            "this view. Truth is what is helpful to the weak, but it is not\n",
            "what is helpful to the stronger; it is what is helpful to the mind, and\n",
            "is not helpful to the body of negative knowledge.\n",
            "It is with these philosophers that we shall find the controversy concerning\n",
            "truth. The first of the two schools is to be found in the way in which\n",
            "we judge of things, as it is used in the sense of _known_. In this\n",
            "case, what we are actually dealing with is something (or\n",
            "somebody) which the laws of logic or of mathematics or of history can easily be\n",
            "described to us, so that we may apprehend what the matter is, and what\n",
            "it involves for many.\n",
            "\n",
            "The person who is acquainted with the truth about Bertrand Russell will, if he\n",
            "realizes that Russell was an astute man, will develop a new view of the\n",
            "study, in which his achievement is more important than his achievement.\n",
            "The man who is acquainted with the truth about the Seven Years\n",
            "War is then brought back to that time, and, through ignorance of the\n",
            "truths about which he was so perturbed, is led to develop a new view of\n",
            "the study, which is more important than the previous one was.\n",
            "It is chiefly in this new theory that we shall be able to decide\n",
            "what truth is required, in addition to the truth about the\n",
            "study. Before the turn of the century there were newspapers which\n",
            "announceed the discovery of the dates given in the laws of logic, and some\n",
            "minority of philosophers, unaccustomed to the narrow domain of philosophy, adopt\n",
            "this view, believing, as we shall read, that there is a greater mystery\n",
            "behind the workings of the universe than either science or logic can reveal.\n",
            "The great German philosopher Kant, who was the most important of the\n",
            "philosophers of mathematics, maintained that there is such a thing as\n",
            "matter, and that what can be nothing but matter and nothing\n",
            "can be nothing at all. He was very much in favour of the school of thought\n",
            "which has grown up in our schools every year, and which they have defeated\n",
            "with an iron fist. They have defeated the very theory which has convinced human\n",
            "thought by teaching us that there is something much more profound than\n",
            "matter and consciousness. The theory, which has held that anywhere in our\n",
            "world there is a ghost, it has it completely wrong. It cannot exist\n",
            "except through the help of matter, space, and touch, and it cannot exist\n",
            "unless we space-fight it. That is to say, it cannot exist if we cannot\n",
            "see it, for what then is self-contradictory, real or perceived? And Kant\n",
            "was not alone in thinking that the theory must be in some way erroneous\n",
            "than either science or philosophy. A large body of philosophers,\n",
            "who have risen to power since Kant, have held that--and this is\n",
            "important--butversely and historically, the two have\n",
            "coalesced apart. They said that Kant's argument is too narrow is misleading\n",
            "and that his argument is not very strong. To return to the\n",
            "argue that Kant's argument is too narrow is to be expressed in very\n",
            "strong terms, and very difficult to vouchsafe. To begin with, it is not\n",
            "worth while to try to prove how much stronger this argument is than\n",
            "the other arguments which follow. The most we can hope is that a battle\n",
            "between the strong and the weak may develop it, and that a new sort of\n",
            "battle may develop it. This is not possible, because the battle\n",
            "between the two is constantly developing, and therefore inconsistent\n",
            "with the notions of causality and proof would be the first\n",
            "failure to consider the constitution of the universe as a whole. Thus the\n",
            "argue that the whole of creation is a mere collection of things\n",
            "\n",
            "[810 | 1957.88] loss=0.04 avg=0.28\n",
            "[820 | 1981.52] loss=0.06 avg=0.28\n",
            "[830 | 2005.23] loss=0.04 avg=0.28\n",
            "[840 | 2028.99] loss=0.04 avg=0.27\n",
            "[850 | 2052.74] loss=0.04 avg=0.27\n",
            "[860 | 2076.47] loss=0.05 avg=0.26\n",
            "[870 | 2100.15] loss=0.07 avg=0.26\n",
            "[880 | 2123.85] loss=0.04 avg=0.26\n",
            "[890 | 2147.57] loss=0.05 avg=0.25\n",
            "[900 | 2171.27] loss=0.05 avg=0.25\n",
            "[910 | 2194.99] loss=0.04 avg=0.25\n",
            "[920 | 2218.71] loss=0.03 avg=0.24\n",
            "[930 | 2242.41] loss=0.06 avg=0.24\n",
            "[940 | 2266.13] loss=0.04 avg=0.24\n",
            "[950 | 2289.87] loss=0.04 avg=0.23\n",
            "[960 | 2313.61] loss=0.04 avg=0.23\n",
            "[970 | 2337.41] loss=0.05 avg=0.23\n",
            "[980 | 2361.20] loss=0.04 avg=0.22\n",
            "[990 | 2384.96] loss=0.04 avg=0.22\n",
            "[1000 | 2408.71] loss=0.04 avg=0.22\n",
            "Saving checkpoint/fine_tuning_run_2/model-1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ],
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "#sess = gpt2.start_tf_sess()\n",
        "use_memory_saving_gradients = True;\n",
        "only_train_transformer_layers = True;\n",
        "accumulate_gradients = 1;\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='fine_tuning_run_2',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BhIMSKjY7Ui"
      },
      "source": [
        "## 7. Copy checkpoint to / load checkpoint from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onmB3jAKZAZr",
        "outputId": "d45504f4-1f67-4133-c9ef-8fd4dbc6641f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i.e. whatever is not mental, or\n",
            "(2) anything other than thoughts and feelings.\n",
            "\n",
            "It will be seen that nearly all the propositions in the above-quoted extracts have\n",
            "been fulfilled by experienced readers; for their validity is dependent\n",
            "upon the validity of the whole of the preceding knowledge.\n",
            "\n",
            "It will be seen that a knowledge as to physical objects is only\n",
            " possible if we assume that there is a physical object which can be\n",
            "immediately known. If this were so, we should find that, although the object\n",
            "appears immediately known, it is not in fact known to us. It is true that\n",
            "when we say 'the sun is setting', we should not be content with\n",
            "a physical object which we know to be setting, but we should be quite content\n",
            "with a knowledge of the fact that the sun is setting. If the object\n",
            "is not known to us, we be content with a knowledge that the object is not\n",
            "ingitting the sun. But if the object is not known to us, we be content\n",
            "with a knowledge that the object is not vitally concerned with the\n",
            "sun, and the world. Hence we be content with a knowledge that the sun\n",
            "is neither shining nor setting, and that the world is not expanding\n",
            "much or dying.\n",
            "\n",
            "It will be seen that among the objects with which we are acquainted\n",
            "are not included the phoenix, the human personage, the sense-datum,\n",
            "the voice which announces the existence of the object, or, if\n",
            "we are doubtful, the sense-datum itself. Among the objects\n",
            "acquainted by touch are those which hold fixed dates or fornications,\n",
            "such as those of babies and young people. But among those objects\n",
            "acquainted by smell are unaccustomed to contact, and a hostile\n",
            "language might cause them to doubt their acquaintance. Thus, while diminishing\n",
            "familiarity with unfamiliar things, we beleive--correctly, as we be led--that we beleaguered\n",
            "travelers are liable to be mistaken.\n",
            "\n",
            "It will be remembered that at the end of Chapter XI we suggested that\n",
            "there might be two kinds of acquaintance, one kind of immediate knowledge (RSK), the\n",
            "other kind of intuitive knowledge (Ockham's) at any rate as to what it is\n",
            "that we may be acquainted with. So far as immediate knowledge is concerned,\n",
            "Ockham's views as to the nature of the objects directly before our\n",
            "eyes, what objects there are in the universe, and what objects there are\n",
            "in the other world. So close is his acquaintance with the sense-data which,\n",
            "as soon as we turn our head, are directly before our senses, as soon\n",
            "as we know that there is nothing in the world apart from its objects\n",
            "and its perceptions. His immediate knowledge, on the contrary, is\n",
            "brought into being by being led through contemplation of the\n",
            "world in which he is seeing it. When, in ordinary life, we speak of\n",
            "'seeing' the sense-data, we do not mean that the sense-data are in the\n",
            "world of sense, but that they have been contemplated by an impartial mind. Thus\n",
            "apart from being acquainted with an object which is directly\n",
            "before our senses, Ockham's view is true even if we know that it is\n",
            "no longer there.\n",
            "\n",
            "Common words, even proper names, are usually really descriptions. That\n",
            "is to say, the thought in the mind of a person using a proper name\n",
            "correctly can generally only be expressed explicitly if we replace the\n",
            "proper name by a description. Moreover, the description required to\n",
            "express the thought will vary for different people, or for the same\n",
            "person at different times. The only thing constant (so long as the name\n",
            "is rightly used) is the object. But so long as this object is explicitly\n",
            "described, Ockham's proposition will always be true.\n",
            "\n",
            "Thus his proposition is truly known: there is no need to\n",
            "describe it.\n",
            "\n",
            "But what is really known is a _case_ of acquaintance with an object which\n",
            "is no longer there. In this case the proposition is true, since the object\n",
            "was never with me when I was acquainted with the thing. But there are\n",
            "other cases in which acquaintance with an object is a case of acquaintance\n",
            "with a different object. In this way acquaintance with a\n",
            "sense-datum is a case of acquaintance with the object itself.\n",
            "\n",
            "It will be seen that Ockham's proposition is not inconsistent with\n",
            "any of the arguments which have been advanced to support it. Among other\n",
            "things, it asserts that there is a physical object which, so long as\n",
            "it is 'in', there is no reason for having such an object. It also asserts\n",
            "that the sense-data which constitute the perception of the object\n",
            "are impossible to apprehend with our senses unless we are acquainted\n",
            "with a physical object which is incapable\n"
          ]
        }
      ],
      "source": [
        "# Copy to\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name='fine_tuning_run_2')\n",
        "\n",
        "# Load from\n",
        "gpt2.generate(sess, run_name= 'fine_tuning_run_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIz5xfiKcbyk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eqkXaFoWAub"
      },
      "source": [
        "#Anna's Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "xmv4rtyHcdeV",
        "outputId": "5eed8dc0-8d1e-4e27-abf1-903f419cb80d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f1d2544e45c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Clouds_test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m             )\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "\n",
        "data = pd.read_json(\"Clouds_test.json\")\n",
        "#print(data)\n",
        "\n",
        "\n",
        "c = []\n",
        "p=[]\n",
        "o=[]\n",
        "cp = []\n",
        "co = []\n",
        "cpo = []\n",
        "with open('Clouds_test.json', 'r') as f:\n",
        "     data = json.loads(f.read())\n",
        "for x in range(5):\n",
        " if (data['cloud'][x]['type']) == 1 :\n",
        "    c.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 2 :\n",
        "    o.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 3 :\n",
        "    p.append(data['cloud'][x]['name'])\n",
        " if ((data['cloud'][x]['type']) == 1 or (data['cloud'][x]['type']) == 3) :\n",
        "    cp.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) != 0:\n",
        "    cpo.append(data['cloud'][x]['name'])\n",
        " if ((data['cloud'][x]['type']) == 1 or (data['cloud'][x]['type'])==2) :\n",
        "    co.append(data['cloud'][x]['name'])\n",
        "\n",
        "\n",
        "\n",
        "#print(\"I have \" + (random.choice(c)) + \" foo\")\n",
        "\n",
        "for x in cpo:\n",
        "   print(x) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#out = [ x for x in data if x['type'] == '1']\n",
        "#outj = json.dumps(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk8sWkvHZEiM"
      },
      "outputs": [],
      "source": [
        "# Utilities\n",
        "import re\n",
        "\n",
        "\n",
        "def cutOff(s, n):\n",
        "  # Truncates String s after n sentences\n",
        "  m = re.search('(([^!\\.\\?]*[!\\.\\?]){%d})' % (n), s)\n",
        "  found = ''\n",
        "  if m:\n",
        "    found = m.group(1) \n",
        "  return found\n",
        "\n",
        "\n",
        "def stripPrefix(s, prefix):\n",
        "  # Removes a prefix from String s\n",
        "  return s[(len(prefix) + 1):]\n",
        "\n",
        "\n",
        "def stripNewLines(s):\n",
        "  # Remove newline characterss\n",
        "  return s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "\n",
        "\n",
        "def slug(s):\n",
        "  # Create a \"slug\" version of a string\n",
        "  return s.replace(\" \", \"-\").lower()\n",
        "\n",
        "\n",
        "def generateList(seed, nsamples):\n",
        "  # Given a prefix, generate a list of generated continuations\n",
        "  genlist = gpt2.generate(sess,\n",
        "                          model_name=\"124M\",\n",
        "                          length=100,\n",
        "                          temperature=0.7,\n",
        "                          prefix=seed,\n",
        "                          nsamples=nsamples,\n",
        "                          batch_size=nsamples,\n",
        "                          return_as_list=True)\n",
        "  \n",
        "  return genlist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jto7imcCe4SF"
      },
      "source": [
        "### Create possible openings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "OWTuF_AHZBh3",
        "outputId": "9a53fd84-2806-404c-e78a-0e1f7a827fd4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-10f4e1b6868a>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    start=That cloud looks like a poodle, which makes me wonder if the\"\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Openings - change this to test out new prompts\n",
        "#start = \"When I look up at the clouds, I like to imagine they are the work of some master sculptor. I wonder\"\n",
        "import array as arr\n",
        "#start = []\n",
        "\n",
        "#for x in range(3):\n",
        "#for x in range(1):\n",
        "start=\"That cloud looks like a poodle, which makes me wonder if the\"\n",
        "\n",
        "\n",
        "print(start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbF2n6kZxDo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9126cd0e-689b-48c7-c69f-0929055768ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8uFke_1dkTZ"
      },
      "outputs": [],
      "source": [
        "#nopenings = 1\n",
        "#nsentences = 1\n",
        "#openings= []\n",
        "#for i in range(1):\n",
        "#openings.append([cutOff(stripNewLines(item), nsentences) for item in generateList(start, nopenings)])\n",
        "\n",
        "#for opening in openings:\n",
        "  #print(opening)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start=\"That cloud looks like a poodle, which makes me wonder if the\"\n",
        "\n",
        "\n",
        "#print(start)\n",
        "\n",
        "nopenings = 1\n",
        "nsentences = 1\n",
        "openings= []\n",
        "#for i in range(1):\n",
        "opnings.append([cutOff(stripNewLines(item), nsentences) for item in generateList(start, nopenings)])\n",
        "\n",
        "for opening in openings:\n",
        "  print(opening)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "OsJDASQrqtHv",
        "outputId": "c88e26dd-8089-4b2c-8516-c90dc563fc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7aa47c1bbe02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mopenings\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#for i in range(1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mopnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutOff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstripNewLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerateList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnopenings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mopening\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopenings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opnings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio UI"
      ],
      "metadata": {
        "id": "VXnWeG2zoV0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "start=input(\"\")\n",
        "\n",
        "\n",
        "#print(start)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nopenings = 1\n",
        "nsentences = 1\n",
        "openings= []\n",
        "#for i in range(1):\n",
        "openings.append([cutOff(stripNewLines(item), nsentences) for item in generateList(start, nopenings)])\n",
        "\n",
        "for opening in openings:\n",
        "  print(opening)\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5BZaicDai07",
        "outputId": "0006e825-676c-4769-f610-edf30449a0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This cloud looks like a baloon\n",
            "['This cloud looks like a baloon, and the sense-datum it contains is not physical, but mental.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(start):\n",
        "    return opening\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "EQGU_gSt0a1A",
        "outputId": "dd57954d-ce92-4a69-a646-588405fc9ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://6f799f137876cede.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6f799f137876cede.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7ef8ae802a90>,\n",
              " 'http://127.0.0.1:7879/',\n",
              " 'https://6f799f137876cede.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wfoRixfSPn8"
      },
      "source": [
        "### Writing back Opening to JSON -- last cell to run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clouds_no = 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB6iLXJG9kpw",
        "outputId": "02cfbca6-14ab-4fd7-bc09-647594b1cc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['That cloud looks like a poodle, which makes me wonder if the poodle \\xa0is actually a person who lives and dies in Edinburgh.'], ['That cloud looks like a poodle, which makes me wonder if the telephone ____ is a mere appearance.'], [\"That cloud looks like a poodle, which makes me wonder if the business_woman \\xa0is an ambiguous person--if only there were such 'facts' as 'objects', 'people', 'savages', and so on.\"], ['That cloud looks like a telephone, which makes me wonder if the poodle �� is also a person with which I am acquainted.'], ['That cloud looks like a telephone, which makes me wonder if the telephone ix is even as it is to the eye.'], ['That cloud looks like a telephone, which makes me wonder if the business_woman ires a valid name.'], ['That cloud looks like a business_woman, which makes me wonder if the poodle �� was in fact a business person.'], ['That cloud looks like a business_woman, which makes me wonder if the telephone ____ is real at all.'], ['That cloud looks like a business_woman, which makes me wonder if the business_woman  consists only of women.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbf8Qs6cSPXx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def write_json(data, filename= \"Clouds_test.json\"):\n",
        "   with open(filename, \"w\") as f:\n",
        "      json.dump(data,f,indent=4)\n",
        "\n",
        "for x in range(1,clouds_no+1):\n",
        " with open(\"Clouds_test.json\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    temp = data['cloud'][x]['bindings']\n",
        "    \n",
        "    for z in range(clouds_no*(x-1),((clouds_no*(x-1))+clouds_no)):\n",
        "        m=  {  \"name\": cpo[z-clouds_no*(x-1)],  \"dialog\": openings[z]}\n",
        "        temp.append(m)\n",
        " write_json(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGwVwH-bsdGi"
      },
      "source": [
        "### Expand on an opening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwTt8DM2io-P"
      },
      "outputs": [],
      "source": [
        "opening = \"The clouds are the work of some master sculptor. \"\n",
        "clouds = [\n",
        "           'telephone', 'teapot', 'table lamp', 'scissors',\n",
        "           'scales of justice', 'high heeled shoe', 'candle']\n",
        "          # 'bucket', 'banana', 'ak47', 'jumping cat',\n",
        "          # 'hammerhead shark', 'flamingo', 'dancing spider',\n",
        "          # 'singing crocodile', 'walrus wearing a hat',\n",
        "          # 'rooster', 'poodle', 'unicorn', 'penguin smoking a pipe',\n",
        "          #'business woman', 'batter waiting for a ball',]\n",
        "          #'kung fu master', 'moon fairy', 'person with a walking cane',]\n",
        "          # 'someone watering a fish', 'girl talking to a horse', 'witch with a cat',\n",
        "          # 'surfer', 'entertainer']\n",
        "\n",
        "# Composition logic\n",
        "nopenings = 1\n",
        "nmicrostories = 1\n",
        "\n",
        "\n",
        "def compose():\n",
        "  rows = []\n",
        "  # Create header\n",
        "  rows += [\"opening\\t\" + \"\\t\".join([slug(str(cloud)) for cloud in clouds])]\n",
        "\n",
        "  newrow = opening\n",
        "  # For each cloud...\n",
        "  for cloud in clouds:\n",
        "    # secret_prefix = \"%s That cloud looks like a %s.\" % (opening, cloud)\n",
        "    secret_prefix = \"\"\n",
        "    shared_prefix = \"The sculptor's %s\" % (cloud)\n",
        "    # prefix = \"%s %s\" % (secret_prefix, shared_prefix)\n",
        "    prefix = shared_prefix\n",
        "    # Generate a list of microstories\n",
        "    microstories = [stripNewLines(stripPrefix(cutOff(story, 6), secret_prefix))\n",
        "                    for story in generateList(seed=prefix,nsamples=nmicrostories)]\n",
        "    # Print the microstories\n",
        "    for story in microstories:\n",
        "      newrow += \"\\t%s\" % (story)\n",
        "  rows.append(newrow)\n",
        "\n",
        "  # Print rows\n",
        "  for row in rows:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chR9-A5uZltY",
        "outputId": "8cd17101-b387-4cdd-8d6d-713da2ef6e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opening\ttelephone\tteapot\ttable-lamp\tscissors\tscales-of-justice\thigh-heeled-shoe\tcandle\n",
            "The clouds are the work of some master sculptor. \t\t\t\t\t\t\t\n"
          ]
        }
      ],
      "source": [
        "compose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VnfZikDX-3H",
        "outputId": "e656dbe5-bece-457f-c7bd-d5b74600e4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot, which is to say, the spectator, is the first to see the piece, and the actual spectator is the same as the painter before him. The painter, in order to be truly recognized, must first of all make him look like the piece in question; secondly, he must make him seem 'real'.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot, as it happens, is a very particular kind of thing, and any attempt to anticipate its appearance will rob the painter of the sense of direction in which he paints; thus, he becomes quite in the dark as to its true nature. The painter, by contrast, always appears to have an intuitive knowledge of the universe, and to have the power of _immediate_ upon knowing this knowledge.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot is the permanent object of his love for the thing. It is his _will_ that the thing be teapotged.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot is the permanent representative of the painter's mind in the world of the painter. The painter's mind is the permanent medium through which the painter's ideas are communicated to the spectator.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot, obviously, is the permanent object of the artist's attention; the subject, in the painter's sense, is merely the person in the artist's life who has been in contact with the artist's mind in the past. The subject, in the painter's sense, is merely the person in the painter's sense who has had some acquaintance with the painter's mind in the past.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot, by definition, must have the innate appearance of _not_ a _piece_ of teapot, but a _complex_ whole, with its parts arranged in a certain order according to the order of the table. The painter's first complete complex is the whole of _the_ table, including the parts that did not go in front of him.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot is the first permanent part of a house, and the roof and all the other surfaces of the house from the outside to the inside. The sculptor's first masterpiece is called the porch.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot, as we shall see, is of a shade of brown to a colour which is quite different from that experienced by a spectator. The colour is of a very different hue, and the painter has little reason to prefer one shade over the other.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot is the permanent object of his imagination, or rather, of all imagination. He has vivid imagination, and he makes vivid distinctions between things and things without at the same time allowing for subtler distinctions.\n",
            "The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the teapot. The teapot, as it happens, is of a shade of pink, and the painter wants the spectator to know that the colour is pink. The painter wants the colour to change as the colour of the prismhener changes, so that when the rose petals rise, the spectator can see the rose petals differently; the colour is pink, and the different people who see the same rose also see the rose differently.\n"
          ]
        }
      ],
      "source": [
        "cloud = \"teapot\"\n",
        "start = \"The clouds are the work of some master sculptor. The sculptor's first masterpiece is titled the %s. The %s\" % (cloud, cloud)\n",
        "nstories = 10\n",
        "nsentences = 4\n",
        "stories = [cutOff(stripNewLines(item), nsentences) for item in generateList(start, nstories)]\n",
        "\n",
        "for story in stories:\n",
        "  print(story)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He6fpnC0Bhq8"
      },
      "source": [
        "# 8. Lavannya's Prompt Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnlozCiaQ7T5",
        "outputId": "1a84a774-07a2-4dd5-d79a-72fec06a23d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "poodle\n",
            "penguin\n",
            "poodle\n",
            "flamingo\n",
            "spider\n",
            "rooster\n",
            "unicorn\n",
            "The bucket was not particularly special, but it was loved by the AK-47 When the businesswoman encountered the candle, I’ve never seen a rooster with a AK-47 but now I see penguin and shoe. They might seem unrelated, but did you know when the rooster and the telephone met, they \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "\n",
        "#data = pd.read_json(\"Clouds.json\")\n",
        "#print(data)\n",
        "\n",
        "\n",
        "c = []\n",
        "p=[]\n",
        "o=[]\n",
        "cp = []\n",
        "co = []\n",
        "cpo = []\n",
        "with open('Clouds.json', 'r') as f:\n",
        "     data = json.loads(f.read())\n",
        "for x in range(18):\n",
        " if (data['cloud'][x]['type']) == 1 :\n",
        "    c.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 2 :\n",
        "    o.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 3 :\n",
        "    p.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 1 or 3 :\n",
        "    cp.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 1 or 2 or 3 :\n",
        "    cpo.append(data['cloud'][x]['name'])\n",
        " if (data['cloud'][x]['type']) == 1 or 2 :\n",
        "    co.append(data['cloud'][x]['name'])\n",
        "\n",
        "\n",
        "\n",
        "#print(\"I have \" + (random.choice(c)) + \" foo\")\n",
        "\n",
        "for x in c:\n",
        "   print(x) \n",
        "\n",
        "print(\"The \" + (random.choice(o)) + \" was not particularly special, but it was loved by the \" + (random.choice(cp)) +\n",
        "\" When the \" + (random.choice(p)) + \" encountered the \" + (random.choice(cp)) + \", I’ve never seen a \" + (random.choice(c)) + \" with a \" + (random.choice(co)) + \" but now I see \" + (random.choice(cpo)) + \" and \" + (random.choice(cpo)) + \". They might seem unrelated, but did you know when the \" + (random.choice(c)) + \" and the \" + (random.choice(cp)) +\" met, they \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#out = [ x for x in data if x['type'] == '1']\n",
        "#outj = json.dumps(out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUckAlws5UzJ"
      },
      "source": [
        "Run this again for next out put"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHA9PnrD6gXY"
      },
      "source": [
        "adjust this sentence based on what you want to prompt, use +(random.choice(c))+ to input a \" creature cloud from the JSON file +(random.choice(o))+ for an object cloud. +(random.choice(p))+ for a Person cloud. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v-8CNyXRB0b"
      },
      "outputs": [],
      "source": [
        "sentence = \"I’ve never seen a \" + (random.choice(c)) +  \" with a \" + (random.choice(o)) + \" \"\n",
        "\n",
        "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## 8. Generate text from the tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh95j2ZsesMb"
      },
      "source": [
        "The next two cells start a Tensorflow session, then set up some utilities that we'll use later. \n",
        "\n",
        "**Run entire (8) again, after running previous cell**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CrQUjkcbDBc"
      },
      "outputs": [],
      "source": [
        "output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO7gUSZWO_tP",
        "outputId": "7811a76e-12ee-4736-9f03-5f2061955a05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   40,   447,   247,   303,  1239,  1775,   257, 19230,   351,   257,\n",
              "         11426,   220,   447,   103,     2, 48261,  2777,  1304,   447,   105,\n",
              "           526,   198,   198,     1,    40,   836,   470,   760,   644,   345,\n",
              "           821,  3375,   546,   553,   314,   531,    13,   366,    40,  1053,\n",
              "          1239,   772,  1775,   530,   878,    11,   290,   314,  1101,   407,\n",
              "           772,  1654,   314,  1053,  1683,  1775,  1997,   588,   340,    13,\n",
              "           314,  1612,    11,   340,   338,   407,   588,   612,   338,   257,\n",
              "          2187,  1256,   286, 26120,   503,   612,    11,   475,   612,   389,\n",
              "           257,  1256,   517,   286,   606,   621,   612,   973,   284,   307,\n",
              "            13,   632,   338,  1611,   286,  1327,   284,  1560,   644,   338]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "bJUE0T8xPdVO",
        "outputId": "55a0dfcf-b006-4345-d191-ab2dfa2c19aa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I’ve never seen a spider with a telephone \\u202a#\\u200espider\\u202c.\"\\n\\n\"I don\\'t know what you\\'re talking about,\" I said. \"I\\'ve never even seen one before, and I\\'m not even sure I\\'ve ever seen anything like it. I mean, it\\'s not like there\\'s a whole lot of spiders out there, but there are a lot more of them than there used to be. It\\'s kind of hard to tell what\\'s'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(output[0], skip_special_tokens = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpMnIdimQYTm"
      },
      "source": [
        "Import Json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw3KPOxQQY3J",
        "outputId": "a96a2dd5-ad6c-4c1e-b7ea-a63a3e4dae43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'shoe', 'type': 2}\n",
            "{'name': 'poodle', 'type': 1}\n",
            "{'name': 'penguin', 'type': 1}\n",
            "{'name': 'telephone', 'type': 2}\n",
            "{'name': 'tea pot', 'type': 2}\n",
            "{'name': 'table lamp', 'type': 2}\n",
            "{'name': 'scissors', 'type': 2}\n",
            "{'name': 'candle', 'type': 2}\n",
            "{'name': 'bucket', 'type': 2}\n",
            "{'name': 'banana', 'type': 2}\n",
            "{'name': 'AK-47', 'type': 2}\n",
            "{'name': 'poodle', 'type': 1}\n",
            "{'name': 'flamingo', 'type': 1}\n",
            "{'name': 'spider', 'type': 1}\n",
            "{'name': 'rooster', 'type': 1}\n",
            "{'name': 'unicorn', 'type': 1}\n",
            "{'name': 'businesswoman', 'type': 3}\n",
            "{'name': 'batter', 'type': 3}\n",
            "{'name': 'kung fu master', 'type': 3}\n",
            "{'name': 'moon fairy', 'type': 3}\n",
            "{'name': 'Person with a walking cane', 'type': 3}\n",
            "{'name': 'Surfer', 'type': 3}\n",
            "{'name': 'Witch', 'type': 3}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Python program to read\n",
        "# json file\n",
        " \n",
        " \n",
        "import json\n",
        " \n",
        "# Opening JSON file\n",
        "f = open('Clouds.json')\n",
        " \n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        " \n",
        "# Iterating through the json\n",
        "# list\n",
        "for i in data['cloud']:\n",
        "    print(i)\n",
        " \n",
        "# Closing file\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQDSc73RW87W"
      },
      "source": [
        "#Optional stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iK1z9rtNsmX"
      },
      "source": [
        "## 9. Generate text from the untuned model (Alternative to 3-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "EB-gFnePNwg9",
        "outputId": "00f569a4-468e-456f-e870-7678d952c59c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-85798d3fcf9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"355M\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gpt2' is not defined"
          ]
        }
      ],
      "source": [
        "model_name=\"355M\"\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "EXrTHzQeOBPc",
        "outputId": "915fff6f-9b32-49cd-c243-7ac765a2eb20"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7b7bbc12a537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gpt2' is not defined"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCG1SQw6RE7Q"
      },
      "outputs": [],
      "source": [
        "# Utilities\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "\n",
        "\n",
        "def cutOff(s, n):\n",
        "  # Truncates String s after n sentences\n",
        "  m = re.search('(([^!\\.\\?]*[!\\.\\?]){%d})' % (n), s)\n",
        "  found = ''\n",
        "  if m:\n",
        "    found = m.group(1) \n",
        "  return found\n",
        "\n",
        "\n",
        "def stripPrefix(s, prefix):\n",
        "  # Removes a prefix from String s\n",
        "  return s[(len(prefix) + 1):]\n",
        "\n",
        "\n",
        "def stripNewLines(s):\n",
        "  # Remove newline characterss\n",
        "  return s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "\n",
        "\n",
        "def slug(s):\n",
        "  # Create a \"slug\" version of a string\n",
        "  return s.replace(\" \", \"-\").lower()\n",
        "\n",
        "\n",
        "def generateList(seed, nsamples):\n",
        "  # Given a prefix, generate a list of generated continuations\n",
        "  genlist = gpt2.generate(sess,\n",
        "                          model_name=\"355M\",\n",
        "                          length=100,\n",
        "                          temperature=0.7,\n",
        "                          prefix=seed,\n",
        "                          nsamples=nsamples,\n",
        "                          batch_size=nsamples,\n",
        "                          return_as_list=True)\n",
        "  return genlist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vefw-p8dZT4J"
      },
      "source": [
        "seeds = [\"unicorn\"]\n",
        "\n",
        "def gen(seed):\n",
        "  nstories = 20 # number of distinct gpt2 runs, each starting with seed\n",
        "  nsentences = 3 # number of sentences to let a single gpt2 run go\n",
        "  openings = [cutOff(stripNewLines(item), nsentences) for item in generateList(seed, nstories)]\n",
        "\n",
        "  for opening in openings:\n",
        "    print(opening)\n",
        "\n",
        "for seed in seeds:\n",
        "  print(\"------\")\n",
        "  gen(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IGTKLgAFP1uG",
        "outputId": "008d0773-a7e1-4948-c303-31c48b22afdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-50b90eb79bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcloud\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclouds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-50b90eb79bc4>\u001b[0m in \u001b[0;36mgen\u001b[0;34m(cloud)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnstories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnsentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mstories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcutOff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstripNewLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerateList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-373495c818a1>\u001b[0m in \u001b[0;36mgenerateList\u001b[0;34m(seed, nsamples)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerateList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m# Given a prefix, generate a list of generated continuations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   genlist = gpt2.generate(sess,\n\u001b[0m\u001b[1;32m     36\u001b[0m                           \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"355M\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                           \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gpt2' is not defined"
          ]
        }
      ],
      "source": [
        "clouds = [\"telephone\", \"teapot\"]\n",
        "def gen(cloud):\n",
        "  start = \"When I look up at the clouds, I like to imagine myself in them. They're a source of hope, comfort, and inspiration. That cloud looks like a %s, doesn't it?\" % (cloud)\n",
        "  nstories = 10\n",
        "  nsentences = 5\n",
        "  stories = [cutOff(stripNewLines(item), nsentences) for item in generateList(start, nstories)]\n",
        "\n",
        "  for story in stories:\n",
        "    print(story)\n",
        "\n",
        "for cloud in clouds:\n",
        "  print(\"--------\")\n",
        "  gen(cloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHBhzmA4g1JN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fGwVwH-bsdGi"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}